https://youtu.be/X48VuDVv0do?si=CLfuQV42HTKfx2jj

pod
service
ingress
volumes 
configmap
secrets
statefulset
deployment

Pod ->
-> Abstraction over container
-> It will create layer on container, it will abstract the container runtime so that you can replace them or you dont have to run with any
container tool like docker. Means you can interact with kubernetes layer
-> Usually one application per pod
-> each will get its own get ip(internal)
-> This can die very easily
-> new ip when new pod created
-> when two pods wants to communicate, if they are communicating through ip then when pod dies it will loose ip and come up with new ip,
so, because of that pod will use service for communication

Ingress ->
It will make the external connection with the service to interact with the pods

Ingress -> service -> node -> pod

Configmap ->

It wil have the configuration of the application. Consider if the url changes in the application,
you dont need to rebuild the application. you can just add in configmap because it will directly with the config map.

Secrets -> 
It will the secrets like consider dockerhub url and username and password

Volumes ->

Physical hardware mounting with pod so that if pod destroys no loosing of data

How zero down time will happen?
Service can two methods: Own can permanent ip or loadbalancer.
the replicas of has to be deployed in multiple nodes or single node. If the pod is the down, service will route the traffic to other.
this will happen by Deployments

Deployments (abstraction of pods) ->
It will create more replicas, if pod down, it will make it to spin up again.

StatefulSet -> It is same like Deployments which will help for replicas of pods and autoscaling. It is basically for 
databases. (Databases should be created using statefulset only due to data consistancy). 

----Databases will never be replica using Deployment because 
database has a state which pods are writing or reading, it will have data inconsistancy. So, either it will happen by statefulset or keep 
the db outside k8 cluster.

Stateful can't be easy so mostly databases will be kept outside k8 cluster in general.

-------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------

Worker machine in K8 cluster:

-> Multiple nodes
-> each nodes has multiple pods in it.
-> 3 processes must be installed in every nodes
     1. container runtime
     2. kubelet -> interacts with container runtime and the worker node. It start the pod with container inside and it will assign 
        the resources from node to the container.
     3. kube-proxy -> It will forward the request perfectly and avoid the network overhead . (Example if the db running making request to one
      pod, it will make the forward the request to same node instead of other node)
-> the communication between the pods will happen through the services.


-------------------------------------------------------------------------------------------------------------------------------------
=====================================================================================================================================

Master node:

1. Api server -> When user want to deploy the application, he has to interact with the api server. It is cluster gateway.
It is the gatekeeper kind of for autorized requests. User can query for the resources and other stuffs using k8 client.
request -> api server -> validate request -> other processes

2. schedular -> When you want to create a new pod, api server will communicate with schedular. schedular will decide how much to 
load resources on each node and where to deploy the pod. It will just decide on which node the new pod to be put.

3. Controller manager -> It will have the cluster state means it detects the cluster changes. Consider example, if the pod is died, it will communicate the schedular to reschedule it again (based on resources schedular will decide where to deploy). 
Controller manager -> schedular -> kubelet

4. etcd -> It is the cluster brain. Cluster changes will stored in key value pair. What is cluster health and what resources are available
and did the cluster state change. It will have these information. *** It will not have the application data ***

In general master node will be multiple in cluster, api server will be loadbalanced.

==> How to setup it?
1. get new bare server
2. add the master/worker node processes
3. add it to the cluster

production cluster setup =>

        master  master
--------------------------
 |     |    |    |     |
node node node node node


==================================================================================================================================

Minikube -> Master and worker processes on one machine. Docker runtime preinstalled
-> it will create the virtual box on laptop and the node will run in that.
-> 1 node k8 cluster.
-> minikube has a kubectl dependency.

We can commnunicate with api server by using k8 api, ui or kubectl client.

===================================================================================================================================

LAYER OF ABSTRACTION:

1. Deployment manages replicaset
2. Replicaset manages replica of pod 
3. pod is an abstraction of container

==============================================================================================================================

NAMESPACE:

-> Organise resources in namespace
-> Virtual cluster inside the cluster

4 namespaces by default:

1.  kube-system : These will have system-processes
2.  kube-public : publically accessible data and configmap which contains cluster information (kubectl cluster-info
3.  kube-node-lease : It will have information about heartbeat of nodes and each node has associated lease object in namespace and 
    determines the availability of a node
4. default : resources you create are located here

Uses:

1. Resources grouped in one namespace
2. Conflicts: many teams, same application - (If other teams have almost same configuration, their deployment might replaces another teams if they are in namespace so, better to create namespace)
3. Resource sharing: staging and development - reuse the components in both environment (like nginx-Ingress, ElasticStack and can use for dev and prod in same cluster)

        Staging               Development
        nginx-Ingress         Elastic Stack

Here staging and development envs can use common nginx and Elastic Stack

4. Resource Sharing - Blue green deployment - Means two production blue (current version) and production green (next version of production) in same cluster can use the same resources like nginx-Ingress and ElasticStack

5. Access and resource limits on namespace - Like if both teams are working on same cluster, having the separate namespaces for each team development will be good because there is no accidental delete or edit happen for other teams work because it is in other namespace
which other team dont have access.

(you can set cpu and ram level in namespace)


Characteristics of namespaces -

1. you can't access the most resources from another namespace - Like consider if the two different namespace is calling same db service,
each namespace should have its own configmaps to access the db and incase of secrets also.

    namespace1                namespace2
    configmap1                configmap2
    secret1                   secrte2
     |-----------|----------------|
                 |
              Db Service
 2. Access service in another service - you can access the other namespace service like specifing the namespace in configmap etc

   like my-sqlservice.namespace 

3. Components can't be created within a namespace - volume and nodes, these are accessible across the cluster
   if you want to access those,
  => kubectl api-resources --namespaced=false
  => kubectl api-resources --namespaced=true (it will give the resources of different namespaces)

4. Component if you dont specify will be created in default namespace.



======================================================================================================================

INGRESS:

when you want to access from domain name from outside you can use this.

In yaml file 
-> kind: Ingress and add the paths
-> the service associated 
-> service port
-> host (valid domain name) must mapped to node's ip address which is the entry point
->  Internal service will be of ClusterIP not 
nodeport and loadbalancer.
-> Ingress controller pod must be installed separately

Ingress controller -> It will evaulate all the rules (because there may be many ingress service), managed redirections. And this is the entrypoint to controller
-> There are third party to install it or we have k8s only nginx-ingress controller.

Ingress Controller pod
|
Myapp - ingress -->  my-app service --> my-app pod 

===============================================================================================================

INBUILT nginx-ingress

=> microk8s enable ingress
=> microk8s kubectl get namespaces
NAME              STATUS   AGE
default           Active   5d14h
ingress           Active   2m23s
iranna            Active   3d22h
kube-node-lease   Active   5d14h
kube-public       Active   5d14h
kube-system       Active   5d14h

=> microk8s kubectl get all -n ingress
NAME                                          READY   STATUS    RESTARTS   AGE
pod/nginx-ingress-microk8s-controller-d2n7v   1/1     Running   0          3m3s

NAME                                               DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
daemonset.apps/nginx-ingress-microk8s-controller   1         1         1       1            1           <none>          3m3s

=> microk8s kubectl get pods -n ingress
NAME                                      READY   STATUS    RESTARTS   AGE
nginx-ingress-microk8s-controller-d2n7v   1/1     Running   0          17m

=> microk8s kubectl get nodes -o wide
NAME             STATUS   ROLES    AGE     VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION
        CONTAINER-RUNTIME
ind-5cg9345hy1   Ready    <none>   5d15h   v1.30.4   172.28.52.113   <none>        Ubuntu 22.04.3 LTS   5.15.153.1-microsoft-standard-WSL2   containerd://1.6.28

=> microk8s kubectl logs -n nginx-deployment.yml
=> microk8s kubectl apply -f clusterip-service.yml 
=>  microk8s kubectl apply -f nginx-ingress.yml (these are in loadbalancer folder)

=> logs : microk8s kubectl logs -n ingress nginx-ingress-microk8s-controller-d2n7v -f

=> microk8s kubectl get ingress
NAME            CLASS    HOSTS         ADDRESS     PORTS   AGE
nginx-ingress   public   nginx.local   127.0.0.1   80      15m

=> microk8s describe ingress <ingress name>


in /etc/hosts => node internal ip (172.28.52.113) and add nginx.local domain name and access in browser

===================================================================================================================

Use cases :

It will pass the request from outside to specified path.

1. Multiple path for same host => like same domain name, you just need to define path and service ingress yaml file
2. multiple subdomains or domains
3. It can handle https request => we can configure tls cert using secret

================================================================================================================

HELM:

Packet manager for k8 cluster and distribute them in public and private registry.

===============================================================================================================

VOLUMES:

===============================================================================================================

STATEFULSET:

Like databases -> Which have data storage to track the track of the data. (Kind: StatefulSet)

And stateless handled by kind: Deployment

-> In stateful, the pods will not have the same access or permissions on the db pods. There will be one master pod which will write and
other are worker which will read the data. And all worker do not use physical storage, they have their own replica. So, they need synchronizing the data required. Master is the one allow to change the data, so, slaves need to know about this change and up to data.

-> But when the cluster or pods died we will loose the data. So, persistant volume is required. So, volume should be set for statefulset.
And each pods its own storage it can have its own volume.

-> And volume can be remote storage. because local one will be for specific pod or node.

-> Here next pod created only when previous one created and running

-> And here deletion will happen from last pod. (Deployment will have random hash)

-> the pod will be deleted when the next to it is deleted correctly and successfully.

-> predictable pod name or fixed pod name and fixed individual dns name

-> it is sticky. When pod dies it will have its state and its role and its recreated.

-> Stateful are not perfect for containerized environments


=================================================================================================================

Services:

Each pod is having its own ip address. When pod dies, it comes up with another ip. To have stable ip and as pods are multiple, to have
loadbalancing Services are used.

1. Stable ip address
2. load balancing 
3. loose coupling
4. within and outside the cluster

Type of services;

1. ClusterIP -> it is default,
2. Headless -> Client wants to talk to one node directly, stateful transactions like database.
